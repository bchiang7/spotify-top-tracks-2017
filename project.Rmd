---
title: "Spotify's Top Tracks of 2017"
output: html_notebook
---

By Brittany Chiang

[Spotify's Top Tracks of 2017](https://open.spotify.com/user/spotify/playlist/37i9dQZF1DX7Axsg3uaDZb?si=nlWdcezESwCW5HazmIGi8A)

# Data Acquisition

## Acquisition from API (8 points)

```{r}
library(devtools)
library(stringdist)
devtools::install_github('charlie86/spotifyr')
library(spotifyr)

# Set client ID
Sys.setenv(SPOTIFY_CLIENT_ID = "7cd7c410d1a94e06b4a81e4bda235aa5")
# Set client ID
Sys.setenv(SPOTIFY_CLIENT_SECRET = "d11a4598b7ff4b97b055ba53cfc72606")

# Get access token
access_token <- get_spotify_access_token()

playlist_username <- 'spotify'
playlist_uris <- c("37i9dQZF1DX7Axsg3uaDZb")

raw_data <- get_playlist_audio_features('spotify', playlist_uris)
```

------

## Acquisition from a file (4 points)

```{r}
# write raw data to CSV
write.csv(raw_data, "top2017playlist.csv")

# pull in data from CSV and store in top2017 data frame
top2017 <- read.csv("top2017playlist.csv", header = TRUE, sep = ",")
```

------

# Data Exploration

```{r}
library(dplyr)

glimpse(top2017)
```

------

# Data Cleaning & Shaping

## Parsing of text (4 points)

Removing some unnecessary columns from the data frame to make the data set easier to parse and work with

```{r}
top2017 <- subset(top2017, select = -c(playlist_name, playlist_uri, playlist_tracks_url, playlist_num_tracks, snapshot_id, playlist_img, track_uri, album_img, track_added_at, track_preview_url, track_open_spotify_url))
```


## Check for any missing values in the data set

```{r}
library(Amelia)
missmap(top2017, main = "Missing values vs observed")
```

This is a pretty small and clean data set, and there's no missing values out of the 100 tracks in this playlist.

------

## Normalization/standardization of feature values (4 points)

```{r}
# convert milliseconds to seconds
top2017$duration_ms <- round(top2017$duration_ms / 1000)

# rename column from 'duration_ms' to just 'duration'
colnames(top2017)[17] <- "duration"

# change loudness from negative to positive values since quantitatively the smaller the loudness value louder a song is
top2017$loudness <- - top2017$loudness

# change name of first column to "rank"
colnames(top2017)[1] <- "rank"
```


------

## Exploratory Data Plots (5 points)

Full description of audio features: https://developer.spotify.com/web-api/get-several-audio-features/

```{r}
library(ggplot2)
# Set ggplot theme
theme_set(theme_bw())
```

------

## Detection of Outliers (5 points)
```{r}
# Gets outliers for a given column (outliers are 2 standard deviations from the mean)
# Args: column (vector)
# Returns the rows of the data frame that are outliers for the given column
getOutliers <- function(column) {
  return (top2017[(abs(column - mean(column)) / sd(column)) > 2,])
}
```

------

#### Artists with more than one track in the top 100 playlist

```{r}
# group together artists
top_artists <- group_by(top2017, artist_name)
top_artists <- summarise(top_artists, count = n())
top_artists <- arrange(top_artists, desc(count))
top_artists <- filter(top_artists, count > 1)

ggplot(top_artists, aes(x = reorder(artist_name,count), y = count)) +
  geom_bar(aes(y = count, fill = artist_name), stat = "identity") +
  coord_flip() +
  labs(x = "Artist Name", y = "Number of Tracks", title = "Top Artists of 2017") +
  theme(legend.position = "none", plot.title = element_text(size = 14, face = "bold"))
```

**Conclusion:** Post Malone, Kendrick Lamar, and Drake were the top artists of 2017

------

### Danceability 
Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.

```{r}
danceability <- top2017$danceability

ggplot(data=top2017, aes(danceability)) + 
  geom_histogram(fill = "dodgerblue", col = I("white"), binwidth = 0.01) +
  labs(title = "Audio Feature: Danceability") +
  labs(x = "Danceability", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold")) +
  geom_density(col = 2)

cat("Mean value of danceability: ", mean(danceability))

cat("Number of danceability outliers: ", nrow(getOutliers(danceability)))
```

**Conclusion:** The more danceable the song, the more popular

------

### Energy
A measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.

```{r}
energy <- top2017$energy

ggplot(data=top2017, aes(energy)) + 
  geom_histogram(fill = "dodgerblue", col = I("white"), binwidth = 0.02) +
  labs(title = "Audio Feature: Energy") +
  labs(x = "Energy", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold")) +
  geom_density(col = 2)

cat("Mean value of energy: ", mean(energy))

cat("Number of energy outliers: ", nrow(getOutliers(energy)))
```

**Conclusion:** The distribution of the energy of the top 100 tracks was relatively well dispersed, but mostly mid-to-high energy

------

### Keys of Top Songs

```{r}
song_keys <- top2017 %>%
  group_by(key) %>%
  summarise(n_key = n()) %>%
  arrange(desc(n_key))
    
song_keys$key <- factor(song_keys$key, levels = song_keys$key[order(song_keys$n_key)])

ggplot(song_keys, aes(x = reorder(key,-n_key), y = n_key, fill = reorder(key,-n_key))) +
  geom_bar(stat = "identity") +
  labs(title = "Distribution of the Keys of Top Songs", x = "Keys", y = "Count of Keys on the Top 100") +
  geom_text(aes(label = n_key), position = position_stack(vjust = 0.8)) +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.title = element_text(size=12)) +
  theme(legend.title = element_blank())
```

**Conclusion:** The most common key among the top 100 tracks of 2017 was C# (which is surprising!)

------

### Loudness
The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.

Note: I've inverted the loudness values from negative to positive

```{r}
loudness <- top2017$loudness

ggplot(top2017) +
  geom_density(aes(loudness, fill = "loudness")) + 
  scale_x_continuous(name = "Loudness") +
  scale_y_continuous(name = "Density") +
  ggtitle("Density plot of Loudness") +
  theme(plot.title = element_text(size = 14, face = "bold"),
        text = element_text(size = 12)) +
  theme(legend.title = element_blank()) +
  scale_fill_brewer(palette = "Accent")

cat("Mean value of loudness: ", mean(loudness))

cat("Number of loudness outliers: ", nrow(getOutliers(loudness)))
```

**Conclusion:** The Top 100 Songs are mostly not so loud.

------


### Mode 
Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.

```{r}
ggplot(data=top2017, aes(top2017$mode, ..count..)) + 
  geom_bar(stat = "count", fill = "dodgerblue", width=0.5) +
  labs(title = "Major vs Minor Tracks") +
  labs(x = "Mode", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold"))
```

**Conclusion:** Major key tracks are preferred over minor key tracks. This is expected, since major key sounds happier than minor key.

------

### Speechiness 
Detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. 

```{r}
speechiness <- top2017$speechiness

ggplot(data=top2017, aes(speechiness)) + 
  geom_histogram(fill = "dodgerblue", col = I("white"), binwidth = 0.02) +
  labs(title = "Audio Feature: Speechiness") +
  labs(x = "Speechiness", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold")) +
  geom_density(col = 2)

cat("Mean value of speechiness: ", mean(speechiness))

cat("Number of speechiness outliers: ", nrow(getOutliers(speechiness)))
```

**Conclusion:** The top 100 tracks of 2017 did not contain many spoken words

------

### Acousticness 
A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.

```{r}
acousticness <- top2017$acousticness

ggplot(data=top2017, aes(acousticness)) + 
  geom_histogram(fill = "dodgerblue", col = I("white"), binwidth = 0.02) +
  labs(title = "Audio Feature: Acousticness") +
  labs(x = "Acousticness", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold")) +
  geom_density(col = 2)


cat("Mean value of acousticness: ", mean(acousticness))

cat("Number of acousticness outliers: ", nrow(getOutliers(acousticness)))
```

**Conclusion:** The top 100 tracks of 2017 were mostly not very acoustic. People don't stream acoustic songs as much as non-acoustic ones.

------

### Liveness 
Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.

```{r}
liveness <- top2017$liveness

ggplot(data=top2017, aes(liveness)) + 
  geom_histogram(fill = "dodgerblue", col = I("white"), binwidth = 0.01) +
  labs(title = "Audio Feature: Liveness") +
  labs(x = "Liveness", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold")) +
  geom_density(col = 2)

cat("Mean value of liveness: ", mean(liveness))

cat("Number of liveness outliers: ", nrow(getOutliers(liveness)))
```

**Conclusion:** As expected, the mean value of liveness was very low, at 0.15. People go to concerts to listen to live music, not spotify.

------


### Valence 
A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).

```{r}
valence <- top2017$valence

ggplot(data=top2017, aes(valence)) + 
  geom_histogram(fill = "dodgerblue", col = I("white"), binwidth = 0.02) +
  labs(title = "Audio Feature: Valence") +
  labs(x = "Valence", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold")) +
  geom_density(col = 2)

cat("Mean value of valence: ", mean(valence))

cat("Number of valence outliers: ", nrow(getOutliers(valence)))
```


**Conclusion:** Happy and sad songs are actually pretty normally distributed at 0.473. The distribution of happy and sad songs is pretty even.

------


### Tempo 
The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.

```{r}
tempo <- as.numeric(as.character(top2017$tempo))

ggplot(data=top2017, aes(tempo)) + 
  geom_histogram(fill = "dodgerblue", col = I("white"), binwidth = 10) +
  labs(title = "Audio Feature: Tempo") +
  labs(x = "Tempo", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold"))

cat("Mean value of tempo: ", mean(tempo))

cat("Number of tempo outliers: ", nrow(getOutliers(tempo)))
```


**Conclusion:** The most popular tempo of a track generally ranges between 100 BPM And 150 BPM.

------

[Tempo Markings](https://en.wikipedia.org/wiki/Tempo)

* Grave – very slow (25–45 bpm)
* Largo – broadly (40–60 bpm)
* Larghetto – rather broadly (60–66 bpm)
* Adagio – slowly with great expression (66–76 bpm)
* Andante – at a walking pace (76–108 bpm)
* Moderato – at a moderate speed (108–120 bpm)
* Allegro – fast, quickly, and bright (120–156 bpm)
* Vivace – lively and fast (156–176 bpm)
* Presto – very, very fast (176–200 bpm)
* Prestissimo – even faster than presto (200 bpm and over)

------

## Feature engineering: new derived features (4 points)

```{r}
# add a new column called tempo_marking based on grouping above

assignTempoMarking <- function(x) {
  tempo <- as.numeric(as.character(x['tempo']))
  
  if (tempo > 25 & tempo < 45) {
    return("grave")
  } else if (tempo > 40 & tempo < 60) {
    return("largo")
  } else if (tempo > 60 & tempo < 66) {
    return("larghetto")
  } else if (tempo > 66 & tempo < 76) {
    return("adagio")
  } else if (tempo > 76 & tempo < 108) {
    return("andante")
  } else if (tempo > 108 & tempo < 120) {
    return("moderato")
  } else if (tempo > 120 & tempo < 156) {
    return("allegro")
  } else if (tempo > 156 & tempo < 176) {
    return("vivace")
  } else if (tempo > 176 & tempo < 200) {
    return("presto")
  } else if (tempo > 200) {
    return("prestissimo")
  }
}

top2017$tempo_marking <- apply(top2017, 1, assignTempoMarking)
```

------

Group tempo markings together to plot

```{r}
# group tempo markings
markings <- top2017 %>%
  group_by(tempo_marking) %>%
  summarise(n_marking = n()) %>%
  arrange(desc(n_marking))

ggplot(markings, aes(x = tempo_marking, y = n_marking, fill = tempo_marking)) +
  geom_bar(stat = "identity") +
  labs(title = "Tempo Markings", x = "Classification", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.title = element_text(size=12)) +
  theme(legend.title = element_blank())
```
**Conclusion:** The most popular tempo classifications were allegro and andante (76-156 BPM)

------


### Duration (in seconds)

```{r}
duration <- top2017$duration

ggplot(data=top2017, aes(duration)) + 
  geom_histogram(fill = "dodgerblue", col = I("white"), binwidth = 5) +
  labs(title = "Audio Feature: Duration") +
  labs(x = "Duration", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold"))


cat("Mean value of duration: ", mean(duration))

cat("Number of duration outliers: ", nrow(getOutliers(duration)))
```

**Conclusion:** The mean duration of the top 100 tracks is 221 seconds, which is about 3 minutes and 41 seconds (3:41). People don't like songs that are too long.


------


### Time Signature
An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).

```{r}
time_signature <- top2017$time_signature

ggplot(data=top2017, aes(time_signature, ..count..)) + 
  geom_bar(stat = "count", fill = "dodgerblue", width = 0.5) +
  labs(title = "Audio Feature: Time Signature") +
  labs(x = "Time Signature", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold"))

cat("Mean value of time signature: ", mean(time_signature))

cat("Number of time signature outliers: ", nrow(getOutliers(time_signature)))
```

**Conclusion:** The majority of top 100 tracks are in a 4/4 time signature.

------


#### Min-Max Normalization

```{r}
top2017numeric <- subset(top2017, select = -c(rank, track_name, artist_name, album_name, key, mode, time_signature, key_mode, tempo_marking))

# min max normalization for factors not already scaled from 0 to 1
minmax <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

top2017$track_popularity <- minmax(top2017numeric$track_popularity)
top2017$loudness <- minmax(top2017numeric$loudness)
top2017$tempo <- minmax(top2017numeric$tempo)
top2017$duration <- minmax(top2017numeric$duration)

top2017numeric$track_popularity <- minmax(top2017numeric$track_popularity)
top2017numeric$loudness <- minmax(top2017numeric$loudness)
top2017numeric$tempo <- minmax(top2017numeric$tempo)
top2017numeric$duration <- minmax(top2017numeric$duration)
```


## Correlation/collinearity analysis (5 points)

In order to understand the correlation between variables, I’ll use corrplot function, which is one of the base data visualization functions.

```{r}
library(corrplot)
cor <- cor(top2017numeric)
corrplot(cor, method= "ellipse", type = "upper", tl.srt = 45)
```

It looks like `speechiness` and `loudness` are positively correlated with each other.

Also, `valence` is positively correlated with `danceability` and `energy`. Considering happy songs make people energetic and want to dance, the correlation obviously makes sense.

Interestingly enough, `energy` and `loudness` are very negatively correlated.

------

As seen above, energy, valence, and danceability are positively correlated. Let’s see how these variables are distributed over 100 songs.

```{r}
ggplot(top2017) +
  geom_density(aes(energy, fill = "energy", alpha=0.1)) + 
  geom_density(aes(valence, fill = "valence", alpha=0.1)) + 
  geom_density(aes(danceability, fill = "danceability", alpha=0.1)) + 
  scale_x_continuous(name = "Energy, Valence and Danceability") +
  scale_y_continuous(name = "Density") +
  ggtitle("Density plot of Energy, Valence and Danceability") +
  theme_bw() +
  theme(plot.title = element_text(size = 14, face = "bold"),
        text = element_text(size = 12)) +
  theme(legend.title = element_blank()) +
  scale_fill_brewer(palette = "Pastel1")
```


------

# Data Storage and Retrieval

## Data stored in a relational database (2 points)

```{r}
library(RMySQL)

# connect to to MySQL
db <- dbConnect(MySQL(), user = "username", password = "password", host = "localhost")

# make sure the connection is all set
summary(db)
dbGetInfo(db)
```


```{r}
# create the database
dbSendQuery(db, "DROP DATABASE IF EXISTS top2017db;")
dbSendQuery(db, "CREATE DATABASE top2017db;")

# tell MySQL to use that database
dbSendQuery(db, "USE top2017db;")

# reconnect to the database just created
db <- dbConnect(MySQL(), user = "username", password = "password", host = "localhost", dbname = "top2017db")
```


## Multiple tables or objects in database (2 points)

```{r}
# clean up tables first
dbSendQuery(db, "DROP TABLE IF EXISTS top2017, top2017numeric")

# create a table for the top2017 dataframe
dbWriteTable(db, value = top2017, name = "top2017", overwrite=TRUE)

# create a table for the dataframe containing numeric data
dbWriteTable(db, value = top2017numeric, name = "top2017numeric", overwrite=TRUE)

# take a look to see that both tables have been added
dbListTables(db)
```


## Simple retrieval mechanism (5 points)

```{r}
# retrieve data from the database (will come back as a MySQLResult)
# and save the results of the query as a data frame
# The n parameter in the function specifies the number of records to retrieve, using n =-1 retrieves all pending records

res1 <- dbSendQuery(db, "SELECT * FROM top2017;")
data = fetch(res1, n = -1)
dbClearResult(res1)


res2 <- dbSendQuery(db, "SELECT * FROM top2017numeric;")
data_num = fetch(res2, n = -1)
dbClearResult(res2)
```


## Complex joins or selective retrieval mechanism (8 points)

"Joining multiple tables and a filter (WHERE) is a complex join. A complex query would require subqueries, group by, aggregation, etc."

```{r}
pop <- dbSendQuery(db, "SELECT 
                        CASE
                          WHEN track_popularity < 0.49 then '0 - 49'
                          WHEN track_popularity between 0.50 and 0.59 then '50 - 59'
                          WHEN track_popularity between 0.60 and 0.69 then '60 - 69'
                          WHEN track_popularity between 0.70 and 0.79 then '70 - 79'
                          WHEN track_popularity between 0.80 and 0.89 then '80 - 89'
                          WHEN track_popularity between 0.90 and 1 then '90 - 100'
                          ELSE 'other'
                        END as `range`, COUNT(*) as Count
                        FROM top2017 
                        GROUP BY `range`;")

pop_data <- fetch(pop, n = -1)

ggplot(pop_data, aes(x = range, y = Count, fill = range)) +
  geom_bar(stat = "identity") +
  labs(title = "Popularity Ranges", x = "Range", y = "Count") +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.title = element_text(size=12)) +
  theme(legend.title = element_blank())

```

```{r}
# group by mode
mode <- dbSendQuery(db, "SELECT COUNT(*) as Count, Mode 
                         FROM top2017 
                         GROUP BY mode;")
mode_data <- fetch(mode, n = -1)
mode_data

# group by key mode
key_mode <- dbSendQuery(db, "SELECT COUNT(*) as Count, key_mode as KeyMode
                             FROM top2017 
                             GROUP BY key_mode;")
key_mode_data <- fetch(key_mode, n = -1)
key_mode_data

# group by time signature
sig <- dbSendQuery(db, "SELECT COUNT(*) as Count, time_signature as TimeSignature 
                             FROM top2017 
                             GROUP BY time_signature;")
sig_data <- fetch(sig, n = -1)
sig_data

# group by tempo marking
tempo <- dbSendQuery(db, "SELECT COUNT(*) as Count, tempo_marking as TempoMarking 
                         FROM top2017 
                         GROUP BY tempo_marking;")
tempo_data <- fetch(tempo, n = -1)
tempo_data
```


------

### Once all data is retrieved, close the connection to the MySQL database

```{r}
# function to kill DB Connections
killDbConnections <- lapply(dbListConnections(MySQL()), dbDisconnect)

killDbConnections

on.exit(dbDisconnect(db))
```




------



# Model Construction and Evaluation

## Training & validation subsets (5 points)

```{r}
# 50% of the sample size
smp_size <- floor(0.5 * nrow(data))

# set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)

# training data set
train_data <- data[train_ind, ]

# validation data set (all values not in the training data set)
test_data <- data[-train_ind, ]

# save off the test data track popularity column to use to check for the quality of the prediciton
test_pop <- test_data$track_popularity
```

------

## Multiple linear regression model (7 points)

Linear regression is one of the most widely known modeling techniques. It allows you, in short, to use a linear relationship to predict the (average) numerical value of Y for a given value of X with a straight line. This line is called the "regression line".

As a consequence, the linear regression model is `y = ax + b`. The model assumes that the response variable `y` is quantitative.

### Predict the track popularity using all other numeric variables

```{r}
linear_model <- lm(formula = track_popularity ~ danceability + energy + loudness + speechiness + acousticness + liveness + valence + tempo + duration, data = train_data)

summary(linear_model)

pred <- predict(linear_model, test_data)

plot(pred - test_pop)
```

**Evaluation:** None of the p-values are significant (p < 0.05). R-squared and F-statistic are low (not significant)

```{r}
# https://stackoverflow.com/questions/5587676/pull-out-p-values-and-r-squared-from-a-linear-regression/35518814
# gets the model p-value
lmp <- function (modelobject) {
  if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
  f <- summary(modelobject)$fstatistic
  p <- pf(f[1],f[2],f[3],lower.tail=F)
  attributes(p) <- NULL
  return(p)
}

cat("p-value: ", lmp(linear_model))
```

Make a forwards fitting prediction with the model above

```{r}
prediction <- predict(linear_model, data.frame(danceability = 0.9, energy = 0.8, loudness = 0.4, speechiness = 0.1, acousticness = 0.1, liveness = 0.1, valence = 0.5, tempo = 0.7, duration = 0.6))

cat("Prediction of track popularity: ", prediction)
```

Backwards fitting

```{r}
prediction <- predict(linear_model, data.frame(danceability = 0.1, energy = 0.2, loudness = 0.9, speechiness = 0.8, acousticness = 0.9, liveness = 0.8, valence = 0.1, tempo = 0.95, duration = 0.98))

cat("Prediction of track popularity: ", prediction)
```

------

### Predict the track popularity using danceability, speechiness, acousticness, and liveness

```{r}
linear_model <- lm(formula = track_popularity ~ danceability + speechiness + acousticness + liveness, data = train_data)

summary(linear_model)

pred <- predict(linear_model, test_data)

plot(pred - test_pop)
```

**Evaluation:** None of the p-values are significant. R squared is low. F-statistic is okay (0.7299).

```{r}
cat("p-value: ", lmp(linear_model))
```

Make a forwards fitting prediction with the model above

```{r}
prediction <- predict(linear_model, data.frame(danceability = 0.9, speechiness = 0.1, acousticness = 0.1, liveness = 0.1))

cat("Prediction of track popularity: ", prediction)
```

Backwards fitting

```{r}
prediction <- predict(linear_model, data.frame(danceability = 0.1, speechiness = 0.8, acousticness = 0.8, liveness = 0.8))

cat("Prediction of track popularity: ", prediction)
```


------


## Logistic regression model (7 points)

Logistic regression is an instance of classification technique that you can use to predict a qualitative response.

```{r}
logistic_model <- glm(formula = track_popularity ~ danceability + energy + loudness + speechiness + acousticness + liveness + valence + tempo + duration, data = train_data, family = binomial(link='logit'))

summary(logistic_model)

pred <- predict(logistic_model, test_data)

plot(pred - test_pop)
```


Analyze the table of deviance

```{r}
anova(logistic_model, test="Chisq")
```

**Evaluation:** None of the p-values are significant.

------

Make a forwards fitting prediction with the model above

```{r}
prediction <- predict(logistic_model, data.frame(danceability = 0.9, energy = 0.8, loudness = 0.4, speechiness = 0.1, acousticness = 0.1, liveness = 0.1, valence = 0.5, tempo = 0.7, duration = 0.6))

cat("Prediction of track popularity: ", prediction)
```

Backwards fitting

```{r}
prediction <- predict(logistic_model, data.frame(danceability = 0.1, energy = 0.2, loudness = 0.9, speechiness = 0.8, acousticness = 0.9, liveness = 0.8, valence = 0.1, tempo = 0.95, duration = 0.98))

cat("Prediction of track popularity: ", prediction)
```


### Predict the track popularity using danceability, speechiness, acousticness, and liveness

```{r}
logistic_model <- glm(formula = track_popularity ~ danceability + speechiness + acousticness + liveness, data = train_data, family = binomial(link='logit'))

summary(logistic_model)

pred <- predict(logistic_model, test_data)

plot(pred - test_pop)
```


Analyze the table of deviance

```{r}
anova(logistic_model, test="Chisq")
```

**Evaluation:** None of the p-values are significant.

------

Make a forwards fitting prediction with the model above

```{r}
prediction <- predict(logistic_model, data.frame(danceability = 0.9, speechiness = 0.1, acousticness = 0.1, liveness = 0.1))

cat("Prediction of track popularity: ", prediction)
```

Backwards fitting

```{r}
prediction <- predict(logistic_model, data.frame(danceability = 0.1, speechiness = 0.8, acousticness = 0.8, liveness = 0.8))

cat("Prediction of track popularity: ", prediction)
```

------

## Recursive Partitioning and Regression Trees (Other, 5 points)

```{r}
library(rpart)

rpart_model <- rpart(formula = track_popularity ~ danceability + energy + loudness + speechiness + acousticness + liveness + valence + tempo + duration, data = train_data, method = "anova")

# detailed results including surrogate splits
summary(rpart_model)

pred <- predict(rpart_model, test_data)

# plot cross-validation results
plotcp(rpart_model)	

# plot approximate R-squared and relative error for different splits (2 plots). labels are only appropriate for the "anova" method.
rsq.rpart(rpart_model)

# plot decision tree
plot(rpart_model)
text(rpart_model)
```

**Evaluation:** None of the p-values are significant.

Make a forwards fitting prediction with the model above

```{r}
prediction <- predict(rpart_model, data.frame(danceability = 0.9, energy = 0.8, loudness = 0.4, speechiness = 0.1, acousticness = 0.1, liveness = 0.1, valence = 0.5, tempo = 0.7, duration = 0.6))

cat("Prediction of track popularity: ", prediction)
```

Backwards fitting

```{r}
prediction <- predict(rpart_model, data.frame(danceability = 0.1, energy = 0.2, loudness = 0.9, speechiness = 0.8, acousticness = 0.9, liveness = 0.8, valence = 0.1, tempo = 0.95, duration = 0.98))

cat("Prediction of track popularity: ", prediction)
```



------



### Predict the track popularity using danceability, speechiness, acousticness, and liveness

```{r}
rpart_model <- rpart(formula = track_popularity ~ danceability + speechiness + acousticness + liveness, data = train_data, method = "anova")

# detailed results including surrogate splits
summary(rpart_model)

pred <- predict(rpart_model, test_data)

# plot cross-validation results
plotcp(rpart_model)	

# plot approximate R-squared and relative error for different splits (2 plots). labels are only appropriate for the "anova" method.
rsq.rpart(rpart_model)

# plot decision tree
plot(rpart_model)
text(rpart_model)
```


**Evaluation:** None of the p-values are significant.

------

Make a forwards fitting prediction with the model above

```{r}
prediction <- predict(rpart_model, data.frame(danceability = 0.9, speechiness = 0.1, acousticness = 0.1, liveness = 0.1))

cat("Prediction of track popularity: ", prediction)
```

Backwards fitting

```{r}
prediction <- predict(rpart_model, data.frame(danceability = 0.1, speechiness = 0.8, acousticness = 0.8, liveness = 0.8))

cat("Prediction of track popularity: ", prediction)
```



## Evaluation of fit of model (5 points) & Comparison of models (5 points) & Interpretation of results/prediction with interval (5 points)

In the models I constructed, my independent variable was always track popularity. Each prediction I made was predicting the popularity of the track given different dependent variables.

None of the models constructed above had p-values that were significant (p < 0.05). For each type of model, constructed two models and two predictions for each (four predictions per type of model).

The first model included nearly all of the numeric audio features of the tracks:
```
track_popularity ~ danceability + energy + loudness + speechiness + acousticness + liveness + valence + tempo + duration
```

The second model only included danceability, speechiness, acousticness, and liveness as the dependent variables.
```
track_popularity ~ danceability + speechiness + acousticness + liveness
```

For both models of each model type, I conducted forward fitting and backwards fitting predictions. Basically, for the forward fitting predictions, I plugged in values that I thought would make the track popular (high danceability, low acousticness, low liveness, etc.). For the backwards fitting predictions, I plugged in values that I thought would make the track less popular (low danceability, high speechiness, etc.). These values were just estimations based on the data understanding and data preparation steps conducted before the model construction & evaluation section.

Overall, none of the models constructed were statistically significant (p < 0.05), but the model that was closest to being significant was the second multiple linear regression model based on the `danceability`, `speechiness`, `acousticness`, and `liveness` variables. The p-value of this model was 0.57.

------

Link to my slide deck: https://docs.google.com/presentation/d/1Cl4MDQ4sT5aexGMreKPJFxeU_wHigYcV2NknR8Zg3fQ/edit?usp=sharing
